{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY=<PUT_YOUR_API_KEY_HERE>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "houses= ['Stark', 'Lannister', 'Targaryen', 'Baratheon', 'Tyrell']\n",
        "roles = ['Knight', 'Schemer', 'Magician', 'Assassin', 'Ranger']\n",
        "events = [\"The Battle of Blackwater\", \"The Battle of the Bastards\", \"The Destruction of the Iron Throne\"]\n",
        "\n",
        "def gpt35(messages, max_tokens=2048, temperature=0.5, top_p=1, frequency_penalty=0, presence_penalty=0):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        frequency_penalty=frequency_penalty,\n",
        "        presence_penalty=presence_penalty)\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def prepare_stories(houses, roles, events, repeat=3, output_file=\"./data/game_of_thrones_stories.csv\"):\n",
        "    df = pd.DataFrame()\n",
        "    repeat = repeat\n",
        "    for house in houses:\n",
        "        for role in roles:\n",
        "            for event in events:\n",
        "                   for i in range(repeat):\n",
        "                        messages = []\n",
        "                        prompt = f\"\"\"Please describe in 140 characters a segment from Game of Thrones where a person as a {role} from {house} participates in the famous {event} event.\"\"\"\n",
        "                        messages.append({\"role\": \"system\", \"content\": prompt})\n",
        "                        story = gpt35(messages)\n",
        "                        row = {\"house\": house, \"role\": role, \"event\": event, \"story\": story}\n",
        "                        row = pd.DataFrame([row])\n",
        "                        df = pd.concat([df, row], axis=0, ignore_index=True)\n",
        "\n",
        "    df.to_csv(output_file)\n",
        "\n",
        "prepare_stories(houses, roles, events)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Based on your file extension, your file is formatted as a CSV file\n",
            "- Your file contains 225 prompt-completion pairs\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `data/prepared_data_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"data/prepared_data_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 5.53 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['openai', 'tools', 'fine_tunes.prepare_data', '--file', 'data/prepared_data.csv', '--quiet'], returncode=0)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"./data/game_of_thrones_stories.csv\")\n",
        "df['sub_prompt'] = df['house'] + \",\" + df['role'] + \",\" + df['event']\n",
        "prepared_data = df.loc[:,['sub_prompt','story']]\n",
        "prepared_data.rename(columns={'sub_prompt':'prompt', 'story':'completion'}, inplace=True)\n",
        "prepared_data.to_csv('./data/prepared_data.csv',index=False)\n",
        "\n",
        "import subprocess\n",
        "\n",
        "subprocess.run('openai tools fine_tunes.prepare_data --file data/prepared_data.csv --quiet'.split())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload a training file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileObject(id='file-asb1zV2mq5BohXrEaoHSXxiv', bytes=58173, created_at=1701173679, filename='prepared_data_prepared.jsonl', object='file', purpose='fine-tune', status='uploaded', status_details=None)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.files.create(\n",
        "  file=open(\"./data/prepared_data_prepared.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-c3lQmMXsuPjGQ738qFT0BVXm', created_at=1701173806, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='davinci-002', object='fine_tuning.job', organization_id='org-DBwVg7sysubJfocwfalit1g7', result_files=[], status='validating_files', trained_tokens=None, training_file='file-asb1zV2mq5BohXrEaoHSXxiv', validation_file=None)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-asb1zV2mq5BohXrEaoHSXxiv\",\n",
        "  model=\"davinci-002\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# List all fine-tune jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-c3lQmMXsuPjGQ738qFT0BVXm', created_at=1701173806, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-DBwVg7sysubJfocwfalit1g7', result_files=[], status='running', trained_tokens=None, training_file='file-asb1zV2mq5BohXrEaoHSXxiv', validation_file=None), FineTuningJob(id='ftjob-FQfCf8AdC94DI6Ct4jZaKWkp', created_at=1701172961, error=None, fine_tuned_model='ft:davinci-002:personal::8PrBHlJf', finished_at=1701173318, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-DBwVg7sysubJfocwfalit1g7', result_files=['file-wlOKBSKZbNcn5Nmhv1WStpMV'], status='succeeded', trained_tokens=36816, training_file='file-50wAPxerWbHsKf380S8agt9F', validation_file=None)], object='list', has_more=False)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.list(limit=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrieve the state of a fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-c3lQmMXsuPjGQ738qFT0BVXm', created_at=1701173806, error=None, fine_tuned_model='ft:davinci-002:personal::8PrPuy9v', finished_at=1701174225, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='davinci-002', object='fine_tuning.job', organization_id='org-DBwVg7sysubJfocwfalit1g7', result_files=['file-NK6CMKDrrSNCLvDIxrdnUdUE'], status='succeeded', trained_tokens=36816, training_file='file-asb1zV2mq5BohXrEaoHSXxiv', validation_file=None)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.fine_tuning.jobs.retrieve(\"ftjob-c3lQmMXsuPjGQ738qFT0BVXm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " A Targaryen soldier, wielding a dragon-glass spear, joins the Battle of the Bastards. Amidst chaos, they unleash fire and fury upon their enemies, turning the tide of the battle and proving their loyalty to the Mother of Dragons. #GameOfThrones #BattleOfTheBastards\n"
          ]
        }
      ],
      "source": [
        "def write_a_story(prompt):\n",
        "    response = client.completions.create(\n",
        "        model=\"ft:davinci-002:personal::8PrPuy9v\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.7,\n",
        "        max_tokens=2000,\n",
        "        top_p=1,\n",
        "        stop=[\"\\n\"])\n",
        "    return response.choices[0].text\n",
        "\n",
        "prompt = \"Targaryen,Soldier,The Battle of the Bastards ->\"\n",
        "story = write_a_story(prompt=prompt)\n",
        "print(story)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " A Soldier from House Arryn joins The Slaughter of the Starks, fighting valiantly for his house, but his loyalty is soon tested as the chaos unfolds. #GameOfThrones\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Arryn,Soldier,The Slaughter of the Starks ->\"\n",
        "story = write_a_story(prompt=prompt)\n",
        "print(story)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analyzing your fine-tuned model's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14575.22s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-c3lQmMXsuPjGQ738qFT0BVXm\",\n",
            "  \"model\": \"davinci-002\",\n",
            "  \"created_at\": 1701173806,\n",
            "  \"finished_at\": 1701174225,\n",
            "  \"fine_tuned_model\": \"ft:davinci-002:personal::8PrPuy9v\",\n",
            "  \"organization_id\": \"org-DBwVg7sysubJfocwfalit1g7\",\n",
            "  \"result_files\": [\n",
            "    \"file-NK6CMKDrrSNCLvDIxrdnUdUE\"\n",
            "  ],\n",
            "  \"status\": \"succeeded\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-asb1zV2mq5BohXrEaoHSXxiv\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": 3,\n",
            "    \"batch_size\": 1,\n",
            "    \"learning_rate_multiplier\": 2\n",
            "  },\n",
            "  \"trained_tokens\": 36816,\n",
            "  \"error\": null\n",
            "}"
          ]
        }
      ],
      "source": [
        "!curl https://api.openai.com/v1/fine_tuning/jobs/ftjob-c3lQmMXsuPjGQ738qFT0BVXm -H \"Authorization: Bearer $OPENAI_API_KEY\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "15255.29s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 14342    0 14342    0     0   9208      0 --:--:--  0:00:01 --:--:--  9205\n"
          ]
        }
      ],
      "source": [
        "!curl https://api.openai.com/v1/files/file-NK6CMKDrrSNCLvDIxrdnUdUE/content -H \"Authorization: Bearer $OPENAI_API_KEY\" > ./data/model_metrics.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Incremental Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "houses= ['Martell', 'Arryn', 'Greyjoy']\n",
        "roles = ['Soldier', 'Watchman', 'Wildling']\n",
        "events = [\"Ned Stark's Investigation into Jon Arryn's Death\", \"The Slaughter of the Starks\", \"Daenerys Targaryen's Sack of King's Landing\"]\n",
        "\n",
        "new_stories = \"./data/game_of_thrones_stories_more.csv\"\n",
        "prepare_stories(houses, roles, events, output_file=new_stories)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Based on your file extension, your file is formatted as a CSV file\n",
            "- Your file contains 81 prompt-completion pairs. In general, we recommend having at least a few hundred examples. We've found that performance tends to linearly increase for every doubling of the number of examples\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `./data/prepared_data_more_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"./data/prepared_data_more_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 3.56 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CompletedProcess(args=['openai', 'tools', 'fine_tunes.prepare_data', '--file', './data/prepared_data_more.csv', '--quiet'], returncode=0)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(new_stories)\n",
        "df['sub_prompt'] = df['house'] + \",\" + df['role'] + \",\" + df['event']\n",
        "prepared_data = df.loc[:,['sub_prompt','story']]\n",
        "prepared_data.rename(columns={'sub_prompt':'prompt', 'story':'completion'}, inplace=True)\n",
        "new_stories_prepared = './data/prepared_data_more.csv'\n",
        "prepared_data.to_csv(new_stories_prepared, index=False)\n",
        "\n",
        "subprocess.run('openai tools fine_tunes.prepare_data --file ./data/prepared_data_more.csv --quiet'.split())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileObject(id='file-Uc2Zaur7AbifRfNqU76xaBPt', bytes=21143, created_at=1701180109, filename='prepared_data_more_prepared.jsonl', object='file', purpose='fine-tune', status='uploaded', status_details=None)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.files.create(\n",
        "  file=open(\"./data/prepared_data_more_prepared.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-t2SppqlqEQ5fZ16HFESHUaUP', created_at=1701180231, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='ft:davinci-002:personal::8PrPuy9v', object='fine_tuning.job', organization_id='org-DBwVg7sysubJfocwfalit1g7', result_files=[], status='validating_files', trained_tokens=None, training_file='file-Uc2Zaur7AbifRfNqU76xaBPt', validation_file=None)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "from openai.types import fine_tuning\n",
        "client = OpenAI()\n",
        "\n",
        "hyper_parameters = {\n",
        "  \"learning_rate_multiplier\": 0.2\n",
        "}\n",
        "\n",
        "client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-Uc2Zaur7AbifRfNqU76xaBPt\",\n",
        "  model=\"ft:davinci-002:personal::8PrPuy9v\",\n",
        "  hyperparameters=hyper_parameters\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " In a shocking twist, a Watchman from House Greyjoy joins The Slaughter of the Starks, turning on his own kin to claim vengeance for lost loved ones. #GameOfThrones\n"
          ]
        }
      ],
      "source": [
        "fine_tuned = write_a_story(\"Greyjoy,Watchman,The Slaughter of the Starks ->\")\n",
        "print(fine_tuned)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " A Martell soldier, joins the Sack of King's Landing, wielding a flaming spear, slicing through enemies, seeking revenge for House Martell, but questioning their own loyalty amidst the chaos. #GameOfThrones"
          ]
        }
      ],
      "source": [
        "def write_a_story_by_stream(prompt):\n",
        "    response = client.completions.create(\n",
        "        model=\"ft:davinci-002:personal::8PrPuy9v\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.7,\n",
        "        max_tokens=2000,\n",
        "        stream=True,\n",
        "        top_p=1,\n",
        "        stop=[\"\\n\"])\n",
        "    return response\n",
        "\n",
        "response = write_a_story_by_stream(\"Martell,Soldier,Daenerys Targaryen's Sack of King's Landing ->\")\n",
        "\n",
        "for event in response:\n",
        "    event_text = event.choices[0].text\n",
        "    print(event_text, end = '')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai_aesthetics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
