{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY=<PUT_YOUR_API_KEY_HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def twenty_newsgroup_to_csv():\n",
        "    newsgroups_train = fetch_20newsgroups(\n",
        "        subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    df = pd.DataFrame(\n",
        "        [newsgroups_train.data, newsgroups_train.target.tolist()]).T\n",
        "    df.columns = ['text', 'target']\n",
        "\n",
        "    targets = pd.DataFrame(newsgroups_train.target_names, columns=['title'])\n",
        "\n",
        "    out = pd.merge(df, targets, left_on='target', right_index=True)\n",
        "    out.to_csv('./data/20_newsgroup.csv', index=False)\n",
        "\n",
        "\n",
        "twenty_newsgroup_to_csv()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI, RateLimitError\n",
        "import os\n",
        "import tiktoken\n",
        "import backoff\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "embedding_model = \"text-embedding-ada-002\"\n",
        "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
        "batch_size = 10\n",
        "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n",
        "\n",
        "df = pd.read_csv('./data/20_newsgroup.csv')\n",
        "print(\"Number of rows before null filtering:\", len(df))\n",
        "df = df[df['text'].isnull() == False]\n",
        "encoding = tiktoken.get_encoding(embedding_encoding)\n",
        "\n",
        "df[\"n_tokens\"] = df.text.apply(lambda x: len(encoding.encode(x)))\n",
        "print(\"Number of rows before token number filtering:\", len(df))\n",
        "df = df[df.n_tokens <= max_tokens]\n",
        "print(\"Number of rows data used:\", len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def get_embeddings(text, model):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
        "\n",
        "\n",
        "@backoff.on_exception(backoff.expo, RateLimitError, max_time=60, max_tries=10)\n",
        "def get_embeddings_with_backoff(prompts, engine):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(prompts), batch_size):\n",
        "        batch = prompts[i:i+batch_size]\n",
        "        embeddings += get_embeddings(list_of_text=batch, engine=engine)\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "prompts = df.text.tolist()\n",
        "prompt_batches = [prompts[i:i+batch_size]\n",
        "                  for i in range(0, len(prompts), batch_size)]\n",
        "\n",
        "embeddings = []\n",
        "for batch in prompt_batches:\n",
        "    batch_embeddings = get_embeddings_with_backoff(\n",
        "        prompts=batch, engine=embedding_model)\n",
        "    embeddings += batch_embeddings\n",
        "\n",
        "df[\"embedding\"] = embeddings\n",
        "df.to_parquet(\"./data/20_newsgroup_with_embedding.parquet\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "embedding_df = pd.read_parquet(\"./data/20_newsgroup_with_embedding.parquet\")\n",
        "\n",
        "matrix = np.vstack(embedding_df.embedding.values)\n",
        "num_of_clusters = 20\n",
        "\n",
        "kmeans = KMeans(n_clusters=num_of_clusters, init=\"k-means++\", n_init=10, random_state=42)\n",
        "kmeans.fit(matrix)\n",
        "labels = kmeans.labels_\n",
        "embedding_df[\"cluster\"] = labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster</th>\n",
              "      <th>count</th>\n",
              "      <th>rank1</th>\n",
              "      <th>rank1_count</th>\n",
              "      <th>rank2</th>\n",
              "      <th>rank2_count</th>\n",
              "      <th>first_percentage</th>\n",
              "      <th>second_percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>522</td>\n",
              "      <td>rec.autos</td>\n",
              "      <td>432</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>6.0</td>\n",
              "      <td>82.76%</td>\n",
              "      <td>83.91%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>391</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>101</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>85.0</td>\n",
              "      <td>25.83%</td>\n",
              "      <td>47.57%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1060</td>\n",
              "      <td>talk.politics.misc</td>\n",
              "      <td>129</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>60.0</td>\n",
              "      <td>12.17%</td>\n",
              "      <td>17.83%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>381</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "      <td>364</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>1.0</td>\n",
              "      <td>95.54%</td>\n",
              "      <td>95.80%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>783</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>323</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>314.0</td>\n",
              "      <td>41.25%</td>\n",
              "      <td>81.35%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>659</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "      <td>409</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>151.0</td>\n",
              "      <td>62.06%</td>\n",
              "      <td>84.98%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>358</td>\n",
              "      <td>sci.crypt</td>\n",
              "      <td>345</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>1.0</td>\n",
              "      <td>96.37%</td>\n",
              "      <td>96.65%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>84</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>8</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.52%</td>\n",
              "      <td>19.05%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>477</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "      <td>461</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.65%</td>\n",
              "      <td>nan%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>472</td>\n",
              "      <td>sci.space</td>\n",
              "      <td>403</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>1.0</td>\n",
              "      <td>85.38%</td>\n",
              "      <td>85.59%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>443</td>\n",
              "      <td>comp.windows.x</td>\n",
              "      <td>406</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.65%</td>\n",
              "      <td>nan%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>432</td>\n",
              "      <td>talk.politics.mideast</td>\n",
              "      <td>368</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>9.0</td>\n",
              "      <td>85.19%</td>\n",
              "      <td>87.27%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>593</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>334</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>49.0</td>\n",
              "      <td>56.32%</td>\n",
              "      <td>64.59%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>820</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "      <td>406</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>35.0</td>\n",
              "      <td>49.51%</td>\n",
              "      <td>53.78%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>529</td>\n",
              "      <td>misc.forsale</td>\n",
              "      <td>435</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.23%</td>\n",
              "      <td>86.01%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>428</td>\n",
              "      <td>sci.electronics</td>\n",
              "      <td>336</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>21.0</td>\n",
              "      <td>78.50%</td>\n",
              "      <td>83.41%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>760</td>\n",
              "      <td>comp.graphics</td>\n",
              "      <td>274</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "      <td>34.0</td>\n",
              "      <td>36.05%</td>\n",
              "      <td>40.53%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>454</td>\n",
              "      <td>sci.med</td>\n",
              "      <td>419</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>92.29%</td>\n",
              "      <td>nan%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>521</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>218</td>\n",
              "      <td>talk.religion.misc</td>\n",
              "      <td>74.0</td>\n",
              "      <td>41.84%</td>\n",
              "      <td>56.05%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>473</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>457</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>96.62%</td>\n",
              "      <td>nan%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    cluster  count                     rank1  rank1_count  \\\n",
              "0         0    522                 rec.autos          432   \n",
              "1         1    391  comp.sys.ibm.pc.hardware          101   \n",
              "2         2   1060        talk.politics.misc          129   \n",
              "3         3    381           rec.motorcycles          364   \n",
              "4         4    783  comp.sys.ibm.pc.hardware          323   \n",
              "5         5    659    soc.religion.christian          409   \n",
              "6         6    358                 sci.crypt          345   \n",
              "7         7     84   comp.os.ms-windows.misc            8   \n",
              "8         8    477          rec.sport.hockey          461   \n",
              "9         9    472                 sci.space          403   \n",
              "10       10    443            comp.windows.x          406   \n",
              "11       11    432     talk.politics.mideast          368   \n",
              "12       12    593   comp.os.ms-windows.misc          334   \n",
              "13       13    820        talk.politics.guns          406   \n",
              "14       14    529              misc.forsale          435   \n",
              "15       15    428           sci.electronics          336   \n",
              "16       16    760             comp.graphics          274   \n",
              "17       17    454                   sci.med          419   \n",
              "18       18    521               alt.atheism          218   \n",
              "19       19    473        rec.sport.baseball          457   \n",
              "\n",
              "                    rank2  rank2_count first_percentage second_percentage  \n",
              "0   comp.sys.mac.hardware          6.0           82.76%            83.91%  \n",
              "1   comp.sys.mac.hardware         85.0           25.83%            47.57%  \n",
              "2      talk.religion.misc         60.0           12.17%            17.83%  \n",
              "3   comp.sys.mac.hardware          1.0           95.54%            95.80%  \n",
              "4   comp.sys.mac.hardware        314.0           41.25%            81.35%  \n",
              "5      talk.religion.misc        151.0           62.06%            84.98%  \n",
              "6   comp.sys.mac.hardware          1.0           96.37%            96.65%  \n",
              "7   comp.sys.mac.hardware          8.0            9.52%            19.05%  \n",
              "8                       0          0.0           96.65%              nan%  \n",
              "9   comp.sys.mac.hardware          1.0           85.38%            85.59%  \n",
              "10                      0          0.0           91.65%              nan%  \n",
              "11     talk.religion.misc          9.0           85.19%            87.27%  \n",
              "12  comp.sys.mac.hardware         49.0           56.32%            64.59%  \n",
              "13     talk.religion.misc         35.0           49.51%            53.78%  \n",
              "14  comp.sys.mac.hardware         20.0           82.23%            86.01%  \n",
              "15  comp.sys.mac.hardware         21.0           78.50%            83.41%  \n",
              "16  comp.sys.mac.hardware         34.0           36.05%            40.53%  \n",
              "17                      0          0.0           92.29%              nan%  \n",
              "18     talk.religion.misc         74.0           41.84%            56.05%  \n",
              "19                      0          0.0           96.62%              nan%  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Count the number of each cluster\n",
        "new_df = embedding_df.groupby('cluster')['cluster'].count().reset_index(name='count')\n",
        "\n",
        "# Count the number of the most frequent category within this cluster.\n",
        "title_count = embedding_df.groupby(['cluster', 'title']).size().reset_index(name='title_count')\n",
        "first_titles = title_count.groupby('cluster').apply(lambda x: x.nlargest(1, columns=['title_count']))\n",
        "first_titles = first_titles.reset_index(drop=True)\n",
        "new_df = pd.merge(new_df, first_titles[['cluster', 'title', 'title_count']], on='cluster', how='left')\n",
        "new_df = new_df.rename(columns={'title': 'rank1', 'title_count': 'rank1_count'})\n",
        "\n",
        "# Count the number of the second most frequent category within this cluster\n",
        "second_titles = title_count[~title_count['title'].isin(first_titles['title'])]\n",
        "second_titles = second_titles.groupby('cluster').apply(lambda x: x.nlargest(1, columns=['title_count']))\n",
        "second_titles = second_titles.reset_index(drop=True)\n",
        "new_df = pd.merge(new_df, second_titles[['cluster', 'title', 'title_count']], on='cluster', how='left')\n",
        "new_df = new_df.rename(columns={'title': 'rank2', 'title_count': 'rank2_count'})\n",
        "new_df['first_percentage'] = (new_df['rank1_count'] / new_df['count']).map(lambda x: '{:.2%}'.format(x))\n",
        "new_df['second_percentage'] = ((new_df['rank1_count'] + new_df['rank2_count'])/ new_df['count']).map(lambda x: '{:.2%}'.format(x))\n",
        "\n",
        "# Replace missing values with 0\n",
        "new_df.fillna(0, inplace=True)\n",
        "# Output the results\n",
        "from IPython.display import display\n",
        "display(new_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY=<PUT_YOUR_API_KEY_HERE>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster 0, Rank 1: rec.autos, Theme:  Automotive Maintenance and Performance\n",
            "Cluster 1, Rank 1: comp.sys.ibm.pc.hardware, Theme:  Computer Hardware and Software\n",
            "Cluster 2, Rank 1: talk.politics.misc, Theme:  Legal and Political Challenges\n",
            "Cluster 3, Rank 1: rec.motorcycles, Theme:  Motorcycling Safety and Advice\n",
            "Cluster 4, Rank 1: comp.sys.ibm.pc.hardware, Theme:  PC Hardware and Software Upgrades\n",
            "Cluster 5, Rank 1: soc.religion.christian, Theme:  Christian Theology and Practices\n",
            "Cluster 6, Rank 1: sci.crypt, Theme:  Government Surveillance and Crypto Regulations\n",
            "Cluster 7, Rank 1: comp.os.ms-windows.misc, Theme:  International Politics\"\"\"\n",
            "Cluster 8, Rank 1: rec.sport.hockey, Theme:  NHL Team Uniforms & Performance\n",
            "Cluster 9, Rank 1: sci.space, Theme:  Space Exploration and Technology\n",
            "Cluster 10, Rank 1: comp.windows.x, Theme:  X Window System Troubleshooting\n",
            "Cluster 11, Rank 1: talk.politics.mideast, Theme:  Middle East Conflict\n",
            "Cluster 12, Rank 1: comp.os.ms-windows.misc, Theme:  Windows Troubleshooting\n",
            "Cluster 13, Rank 1: talk.politics.guns, Theme:  Civil Rights Violations and Government Accountability\n",
            "Cluster 14, Rank 1: misc.forsale, Theme:  Musical Instruments and Electronics for Sale\n",
            "Cluster 15, Rank 1: sci.electronics, Theme:  Amateur Radio and Electronics\n",
            "Cluster 16, Rank 1: comp.graphics, Theme:  Computer Hardware & Software Specifications\n",
            "Cluster 17, Rank 1: sci.med, Theme:  'Effects of Heavy Water Poisoning'\n",
            "Cluster 18, Rank 1: alt.atheism, Theme:  LGBT Rights and Misconceptions\n",
            "Cluster 19, Rank 1: rec.sport.baseball, Theme:  Baseball Statistics and Analysis\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "items_per_cluster = 10\n",
        "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
        "\n",
        "for i in range(num_of_clusters):\n",
        "    cluster_name = new_df[new_df.cluster == i].iloc[0].rank1\n",
        "    print(f\"Cluster {i}, Rank 1: {cluster_name}, Theme:\", end=\" \")\n",
        "\n",
        "    content = \"\\n\".join(\n",
        "        embedding_df[embedding_df.cluster == i].text.sample(items_per_cluster, random_state=42).values\n",
        "    )\n",
        "    response = client.completions.create(\n",
        "        model=COMPLETIONS_MODEL,\n",
        "        prompt=f'''We would like to categorize the following content into meaningful groups so that we can summarize it. Please name a news group in less than 20 words based on the commonalities in the content below. For example, 'PC Hardware'\\n\\nContent:\\n\"\"\"\\n{content}\\n\"\"\"News Group Name:''',\n",
        "        temperature=0,\n",
        "        max_tokens=100,\n",
        "        top_p=1,\n",
        "    )\n",
        "    print(response.choices[0].text.replace(\"\\n\", \"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The User and Assistant discussed the Los Angeles Chargers, with the Assistant explaining that the team is dealing with injuries but is working hard to stay competitive and address any issues that need improvement.\n"
          ]
        }
      ],
      "source": [
        "history = \"\"\"User : Who are you?\n",
        "Assistant : Hi there! I'm the coach of the Los Angeles Chargers. How can I help you today? #BoltUp\n",
        "\n",
        "User : What is the Los Angeles Chargers' main issue at the moment?\n",
        "Assistant : Injuries have been a challenge for us this season, but we're working hard to overcome them and stay competitive. #StayStrong #BoltUp\n",
        "\n",
        "User : What about other issues?\n",
        "Assistant : Every team faces different challenges, but we're constantly evaluating and adjusting our game plan to address any areas that need improvement. #TeamWork #BoltUp\n",
        "\"\"\"\n",
        "\n",
        "def summarize(text, max_tokens=200):\n",
        "    response = client.completions.create(\n",
        "        model=COMPLETIONS_MODEL,\n",
        "        prompt=text + \"\\n\\nPlease summarize what the User and Assistant discussed above:\\n\",\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return response.choices[0].text\n",
        "\n",
        "summarized = summarize(history)\n",
        "print(summarized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "class Conversation:\n",
        "    def __init__(self, prompt, num_of_rounds):\n",
        "        self.prompt = prompt\n",
        "        self.num_of_rounds = num_of_rounds\n",
        "        self.messages = []\n",
        "        self.messages.append({\"role\": \"system\", \"content\": self.prompt})\n",
        "\n",
        "    def ask(self, question):\n",
        "        try:\n",
        "            self.messages.append({\"role\": \"user\", \"content\": question})\n",
        "            response = client.chat.completions.create(model=\"gpt-3.5-turbo\",\n",
        "            messages=self.messages,\n",
        "            temperature=0.5,\n",
        "            max_tokens=2048,\n",
        "            top_p=1)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            return e\n",
        "\n",
        "        message = response.choices[0].message.content\n",
        "        self.messages.append({\"role\": \"assistant\", \"content\": message})\n",
        "\n",
        "        if len(self.messages) > self.num_of_rounds*2 + 1:\n",
        "            del self.messages[1:3]  # Remove the first round conversation left.\n",
        "        return message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User : How about San Francisco 49ers?\n",
            "Assistant : The San Francisco 49ers have had an interesting season so far. They started off strong but have faced their fair share of challenges, including injuries to key players. Despite that, they have shown resilience and have managed to stay competitive. The team has been working hard to address any issues that need improvement and make adjustments as necessary. It will be interesting to see how they continue to perform throughout the season. Is there anything specific you would like to know about the 49ers?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = summarized + \"\\n\\nBased on the content of the conversation so far, please continue the dialogue:\"\n",
        "conversation = Conversation(prompt, 5)\n",
        "\n",
        "question = \"How about San Francisco 49ers?\"\n",
        "answer = conversation.ask(question)\n",
        "print(\"User : %s\" % question)\n",
        "print(\"Assistant : %s\\n\" % answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User : How about San Francisco 49ers?\n",
            "Assistant : Oh, the San Francisco 49ers! They are a historic team with a rich history in the NFL. They have had some incredible seasons and have won multiple Super Bowls. What do you think of their performance this year?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\\n\\nBased on the content of the conversation so far, please continue the dialogue:\"\n",
        "conversation = Conversation(prompt, 5)\n",
        "\n",
        "question = \"How about San Francisco 49ers?\"\n",
        "answer = conversation.ask(question)\n",
        "print(\"User : %s\" % question)\n",
        "print(\"Assistant : %s\\n\" % answer)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai_aesthetics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
