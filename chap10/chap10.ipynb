{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=<PUT_YOUR_API_KEY_HERE>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, os\n",
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "documents = SimpleDirectoryReader('./source_data').load_data()\n",
    "index = GPTVectorStoreIndex.from_documents(documents)\n",
    "\n",
    "index.storage_context.persist(persist_dir='./data/index_macbook_air_m3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected release date for the MacBook Air based on the M3 processor is sometime in the first half of 2024, between the spring and summer of next year at the earliest.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./data/index_macbook_air_m3\")\n",
    "\n",
    "index = load_index_from_storage(storage_context)\n",
    "query_index = index.as_query_engine()\n",
    "\n",
    "response = query_index.query(\"What is the expected release date for the MacBook Air based on the M3 processor?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 13-inch MacBook Air based on the M2 processor was released in June 2022.\n"
     ]
    }
   ],
   "source": [
    "response = query_index.query(\"When was the 13-inch MacBook Air based on the M2 processor released?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected release date for the MacBook Air based on the M3 processor is sometime in the first half of 2024, between the spring and summer of next year at the earliest.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import QuestionAnswerPrompt\n",
    "query_str = \"What is the expected release date for the MacBook Air based on the M3 processor?\"\n",
    "DEFAULT_TEXT_QA_PROMPT_TMPL = (\n",
    "    \"Context information is below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the question: {query_str}\\n\"\n",
    ")\n",
    "QA_PROMPT = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)\n",
    "\n",
    "query_index = index.as_query_engine(text_qa_template=QA_PROMPT)\n",
    "\n",
    "response = query_index.query(query_str)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not know.\n"
     ]
    }
   ],
   "source": [
    "QA_PROMPT_TMPL = (\n",
    "    \"Based on the following information, where \\\"13-inch\\\" and \\\"15-inch\\\" refer to Apple's MacBook Air \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"please answer the question: {query_str}\\n\"\n",
    "    \"If you do not know the answer, please respond with \\\"I do not know.\\\"\\n\"\n",
    ")\n",
    "QA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)\n",
    "query_index = index.as_query_engine(text_qa_template=QA_PROMPT)\n",
    "response = query_index.query(\"When will the next generation of Google Pixel series smartphones be released?\")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fw/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.indices.list.base.SummaryIndex object at 0x7fac33891a20>\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from llama_index import GPTListIndex, LLMPredictor, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "# define LLM\n",
    "llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", max_tokens=1024))\n",
    "\n",
    "text_splitter = SpacyTextSplitter(pipeline=\"en_core_web_sm\", chunk_size = 2048)\n",
    "parser = SimpleNodeParser(text_splitter=text_splitter)\n",
    "documents = SimpleDirectoryReader('./source_data').load_data()\n",
    "nodes = parser.get_nodes_from_documents(documents)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "\n",
    "list_index = GPTListIndex(nodes=nodes, service_context=service_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is planning to release new versions of the MacBook Air with M3 chips. These models are expected to have similar CPU and GPU core counts as the current M2 chip. The M3 chip is said to be up to 20% faster than the M2 chip. The release of the new MacBook Airs is scheduled for the first half of 2024, with a possible launch between spring and summer. The exact order of release for the 13-inch and 15-inch models is uncertain and may depend on supplier production capacity.\n"
     ]
    }
   ],
   "source": [
    "index = list_index.as_query_engine(response_mode=\"tree_summarize\")\n",
    "response = index.query(\"Please summarize the news about the MacBook Air that was read in the previous steps.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add5133a89b546f3b230517171514705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)netuned-cord-v2/resolve/main/config.json:   0%|          | 0.00/4.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8c50b2a57c4fe687e59f1afc201629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/806M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex\n",
    "from llama_index.readers.file.base import (\n",
    "    DEFAULT_FILE_READER_CLS,\n",
    "    ImageReader,\n",
    ")\n",
    "from llama_index.response.notebook_utils import display_response, display_image\n",
    "from llama_index.indices.query.query_transform.base import ImageOutputQueryTransform\n",
    "\n",
    "image_parser = ImageReader(keep_image=True, parse_text=True)\n",
    "file_extractor = DEFAULT_FILE_READER_CLS\n",
    "file_extractor.update(\n",
    "{\n",
    "    \".jpg\": image_parser,\n",
    "    \".png\": image_parser,\n",
    "    \".jpeg\": image_parser,\n",
    "})\n",
    "\n",
    "# NOTE: we add filename as metadata for all documents\n",
    "filename_fn = lambda filename: {'file_name': filename}\n",
    "\n",
    "receipt_reader = SimpleDirectoryReader(\n",
    "    input_dir='./source_data/receipts',\n",
    "    file_extractor=file_extractor,\n",
    "    file_metadata=filename_fn,\n",
    ")\n",
    "receipt_documents = receipt_reader.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** The last time you went to McDonald's was on March 10, 2018 at 07:39:12 PM. You spent a total of $26.15. Here is the receipt from your visit:\n",
       "\n",
       "QTY ITEM              TOTAL\n",
       "1   10 McNuggets EVM  $10.29\n",
       "1   Barbeque Sauce    $1.00\n",
       "1   Barbeque Sauce    $0.40\n",
       "1   L Coke            $0.40\n",
       "1   M French Fries    $3.99\n",
       "1   HM GrChS S-Fry Yog\n",
       "1   Smoonya\n",
       "1   HM Apple Juice    $2.89\n",
       "6   Cookies           $2.89\n",
       "6   Choc Chip Cookie  $1.19\n",
       "1   Baked Apple Pie   $3.29\n",
       "1   French Fries      $2.99\n",
       "1   Iced Tea          $2.99\n",
       "\n",
       "Subtotal: $25.04\n",
       "Tax: $1.11\n",
       "Total: $26.15"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "receipts_index = GPTVectorStoreIndex.from_documents(receipt_documents)\n",
    "index = receipts_index.as_query_engine(query_transform=ImageOutputQueryTransform(width=400))\n",
    "receipts_response = index.query(\n",
    "    'When was the last time I went to McDonald\\'s and how much did I spend. \\\n",
    "    Also show me the receipt from my visit.'\n",
    ")\n",
    "\n",
    "display_response(receipts_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s_menu><s_nm> Story</s_nm><s_num> 16725 Stony Platin Rd</s_nm><s_num> Store#:</s_nm><s_num> 3659</s_num><s_price> 700-418-8362</s_price><sep/><s_nm> Welcome to all day breakfast dormist O Md Donald's</s_nm><s_num> 192</s_num><s_price> 192</s_price><sep/><s_nm> QTY ITEM</s_nm><s_num> OTAL</s_num><s_unitprice> 03/10/2018</s_unitprice><s_cnt> 1</s_cnt><s_price> 07:39:12 PM</s_price><sep/><s_nm> Delivery</s_nm><s_cnt> 1</s_cnt><s_price> 0.00</s_price><sep/><s_nm> 10 McNuggets EVM</s_nm><s_cnt> 1</s_cnt><s_price> 10.29</s_price><sep/><s_nm> Barbeque Sauce</s_nm><s_cnt> 1</s_cnt><s_price> 1</s_price><sep/><s_nm> Barbeque Sauce</s_nm><s_num> 1</s_cnt><s_price> 0.40</s_price><sep/><s_nm> L Coke</s_nm><s_cnt> 1</s_cnt><s_price> 0.40</s_price><sep/><s_nm> M French Fries</s_nm><s_cnt> 1</s_cnt><s_price> 3.99</s_price><sep/><s_nm> HM GrChS S-Fry Yog</s_nm><s_cnt> 1</s_cnt><sep/><s_nm> Smoonya</s_nm><s_cnt> 1</s_cnt><sep/><s_nm> HM Apple Juice</s_nm><s_cnt> 1</s_cnt><s_price> 2.89</s_price><sep/><s_nm> Cookies</s_nm><s_cnt> 6</s_cnt><s_price> 2.89</s_price><sep/><s_nm> Choc Chip Cookie</s_nm><s_cnt> 6</s_cnt><s_price> 1.19</s_price><sep/><s_nm> Baked Apple Pie</s_nm><s_cnt> 1</s_cnt><s_price> 3.29</s_price><sep/><s_nm> French Fries</s_nm><s_cnt> 1</s_cnt><s_price> 2.99</s_price><sep/><s_nm> Iced Tea</s_nm><s_cnt> 1</s_cnt><s_price> 2.99</s_price></s_menu><s_sub_total><s_subtotal_price> 25.04</s_subtotal_price><s_tax_price> 1.11</s_tax_price></s_sub_total><s_total><s_total_price> 26.15</s_total_price><s_changeprice> 0.00</s_changeprice><s_creditcardprice> 26.15</s_creditcardprice></s_total>\n"
     ]
    }
   ],
   "source": [
    "output_image = image_parser.load_data('./source_data/receipts/1100-receipt.jpg')\n",
    "print(output_image[0].text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_aesthetics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
