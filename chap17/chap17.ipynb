{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY=<PUT_YOUR_API_KEY_HERE>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "llm = ChatOpenAI(max_tokens=2048, temperature=0.5)\n",
        "multiple_choice = \"\"\"\n",
        "Please choose an appropriate tool to answer the user's question between >>> and <<<. Just tell me the answer with the option letters A, B, C. If you think none are suitable, choose D.\n",
        "\n",
        ">>>{question}<<<\n",
        "\n",
        "The tools we have include:\n",
        "A. A tool that can query product information and guide users in product selection\n",
        "B. A tool that can query order information and obtain the latest order status\n",
        "C. A tool that can search for a merchant's return and exchange policy, shipping costs, logistics duration, payment channels, and covered countries\n",
        "D. None are suitable\n",
        "\"\"\"\n",
        "multiple_choice_prompt = PromptTemplate(template=multiple_choice, input_variables=[\"question\"])\n",
        "choice_chain = LLMChain(llm=llm, prompt=multiple_choice_prompt, output_key=\"answer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': \"I want to buy a fingerprint door lock, but I'm not sure which brand offers the best value for money. Can you recommend one for me?\", 'answer': 'A. A tool that can query product information and guide users in product selection'}\n"
          ]
        }
      ],
      "source": [
        "question = \"I want to buy a fingerprint door lock, but I'm not sure which brand offers the best value for money. Can you recommend one for me?\"\n",
        "print(choice_chain(question))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'I have an order with the order number 20231127E12345 that I have not received yet. Could you please help me check it?', 'answer': 'B. A tool that can query order information and obtain the latest order status'}\n"
          ]
        }
      ],
      "source": [
        "question = \"I have an order with the order number 20231127E12345 that I have not received yet. Could you please help me check it?\"\n",
        "print(choice_chain(question))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'Can this product be delivered to Crested Butte in Colorado? How many days will it approximately take?', 'answer': \"C. A tool that can search for a merchant's return and exchange policy, shipping costs, logistics duration, payment channels, and covered countries\"}\n"
          ]
        }
      ],
      "source": [
        "question = \"Can this product be delivered to Crested Butte in Colorado? How many days will it approximately take?\"\n",
        "print(choice_chain(question))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'How has the Los Angeles Chargers performed this season?', 'answer': 'D. None are suitable'}\n"
          ]
        }
      ],
      "source": [
        "question = \"How has the Los Angeles Chargers performed this season?\"\n",
        "print(choice_chain(question))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.llms import openai\n",
        "\n",
        "llm = openai.OpenAI(temperature=0)\n",
        "\n",
        "def search_order(input: str) -> str:\n",
        "    return \"Order status: Shipped; Shipment date: 2023-11-27; Estimated delivery date: 2023-12-01\"\n",
        "\n",
        "def recommend_product(input: str) -> str:\n",
        "    return \"FlexBand Multifunctional Smartwatch\"\n",
        "\n",
        "def faq(intput: str) -> str:\n",
        "    return \"Exclusive Deals\"\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search Order\",func=search_order,\n",
        "        description=\"useful for when you need to answer questions about customers orders\"\n",
        "    ),\n",
        "    Tool(name=\"Recommend Product\", func=recommend_product,\n",
        "         description=\"useful for when you need to answer questions about product recommendations\"\n",
        "    ),\n",
        "    Tool(name=\"FAQ\", func=faq,\n",
        "         description=\"useful for when you need to answer questions about shopping policies, like exclusive deals, return policy, shipping policy, etc.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to recommend a product.\n",
            "Action: Recommend Product\n",
            "Action Input: Smartwatch\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mFlexBand Multifunctional Smartwatch\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to know more about this product.\n",
            "Action: Search Order\n",
            "Action Input: FlexBand Multifunctional Smartwatch\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mOrder status: Shipped; Shipment date: 2023-11-27; Estimated delivery date: 2023-12-01\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The FlexBand Multifunctional Smartwatch is available for purchase and is estimated to be delivered on December 1, 2023.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The FlexBand Multifunctional Smartwatch is available for purchase and is estimated to be delivered on December 1, 2023.\n"
          ]
        }
      ],
      "source": [
        "question = \"I want to buy a smartwatch, but I'm not sure which features would suit me. Can you help me with some recommendations?\"\n",
        "result = agent.run(question)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out the status of the order\n",
            "Action: Search Order\n",
            "Action Input: 20231127D3478E\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mOrder status: Shipped; Shipment date: 2023-11-27; Estimated delivery date: 2023-12-01\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Your order has been shipped on 2023-11-27 and is estimated to be delivered on 2023-12-01.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Your order has been shipped on 2023-11-27 and is estimated to be delivered on 2023-12-01.\n"
          ]
        }
      ],
      "source": [
        "question = \"I have an order with the order number 20231127D3478E. The order status shows as not delivered. Could you please help me check it?\"\n",
        "result = agent.run(question)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out if Amazon Prime members can get a discount on this product.\n",
            "Action: FAQ\n",
            "Action Input: Prime member discount\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mExclusive Deals\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out what exclusive deals are available for Prime members.\n",
            "Action: FAQ\n",
            "Action Input: Exclusive Deals\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mExclusive Deals\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Yes, Amazon Prime members can enjoy exclusive deals on select products.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Yes, Amazon Prime members can enjoy exclusive deals on select products.\n"
          ]
        }
      ],
      "source": [
        "question = \"I am an Amazon Prime member. Can I enjoy a Prime member discount on this smartwatch?\"\n",
        "result = agent.run(question)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out if Amazon Prime members can get a discount on this product.\n",
            "Action: FAQ\n",
            "Action Input: Prime member discount\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mExclusive Deals\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out what exclusive deals are available for Prime members.\n",
            "Action: FAQ\n",
            "Action Input: Exclusive Deals\u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3mExclusive Deals\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "===\n",
            "Agent stopped due to iteration limit or time limit.\n",
            "===\n"
          ]
        }
      ],
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", max_iterations = 2, verbose=True)\n",
        "question = \"I am an Amazon Prime member. Can I enjoy a Prime member discount on this smartwatch?\"\n",
        "result = agent.run(question)\n",
        "print(\"===\")\n",
        "print(result)\n",
        "print(\"===\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fw/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n",
            "Created a chunk of size 434, which is longer than the specified 256\n",
            "Created a chunk of size 466, which is longer than the specified 256\n",
            "/home/fw/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:251: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import faiss\n",
        "from langchain.text_splitter import SpacyTextSplitter\n",
        "from langchain import VectorDBQA\n",
        "from langchain.llms import openai\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "llm = openai.OpenAI(temperature=0)\n",
        "loader = TextLoader('./data/amazon_faq.txt')\n",
        "documents = loader.load()\n",
        "text_splitter = SpacyTextSplitter(chunk_size=256, pipeline=\"en_core_web_sm\")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "docsearch = faiss.FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "faq_chain = VectorDBQA.from_chain_type(llm=llm, vectorstore=docsearch, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import tool\n",
        "\n",
        "@tool(\"FAQ\")\n",
        "def faq(intput: str) -> str:\n",
        "    \"\"\"\"useful for when you need to answer questions about shopping policies, like exclusive deals, return policy, shipping policy, etc.\"\"\"\n",
        "    return faq_chain.run(intput)\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search Order\",func=search_order,\n",
        "        description=\"useful for when you need to answer questions about customers orders\"\n",
        "    ),\n",
        "    Tool(name=\"Recommend Product\", func=recommend_product,\n",
        "         description=\"useful for when you need to answer questions about product recommendations\"\n",
        "    ),\n",
        "    faq\n",
        "]\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out if there is a discount available for Prime members.\n",
            "Action: FAQ\n",
            "Action Input: Prime member discount\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new VectorDBQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m Selling fees and optional services may apply for Prime members. The Amazon Prime badge is available to sellers who use Fulfillment by Amazon (FBA) or Seller Fulfilled Prime (SFP) to handle logistics.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out if there is a discount available for this specific product.\n",
            "Action: Search Order\n",
            "Action Input: Smartwatch\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mOrder status: Shipped; Shipment date: 2023-11-27; Estimated delivery date: 2023-12-01\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: No, there is no Prime member discount available for this specific smartwatch.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "No, there is no Prime member discount available for this specific smartwatch.\n"
          ]
        }
      ],
      "source": [
        "question = \"I am an Amazon Prime member. Can I enjoy a Prime member discount on this smartwatch?\"\n",
        "result = agent.run(question)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fw/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:251: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import CSVLoader\n",
        "\n",
        "product_loader = CSVLoader('./data/realistic_digital_products.csv')\n",
        "product_documents = product_loader.load()\n",
        "product_text_splitter = CharacterTextSplitter(chunk_size=1024, separator=\"\\n\")\n",
        "product_texts = product_text_splitter.split_documents(product_documents)\n",
        "product_search = faiss.FAISS.from_documents(product_texts, OpenAIEmbeddings())\n",
        "product_chain = VectorDBQA.from_chain_type(llm=llm, vectorstore=product_search, verbose=True)\n",
        "\n",
        "@tool(\"FAQ\")\n",
        "def faq(intput: str) -> str:\n",
        "    \"\"\"\"useful for when you need to answer questions about shopping policies, like exclusive deals, return policy, shipping policy, etc.\"\"\"\n",
        "    return faq_chain.run(intput)\n",
        "\n",
        "@tool(\"Recommend Product\")\n",
        "def recommend_product(input: str) -> str:\n",
        "    \"\"\"\"useful for when you need to search and recommend products and recommend it to the user\"\"\"\n",
        "    return product_chain.run(input)\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Search Order\",func=search_order,\n",
        "        description=\"useful for when you need to answer questions about customers orders\"\n",
        "    ),\n",
        "    recommend_product, faq]\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find a product that meets the customer's needs.\n",
            "Action: Recommend Product\n",
            "Action Input: Security cameras that need to be installed at the front door and living room, controllable and viewable remotely via a smartphone\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new VectorDBQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[33;1m\u001b[1;3m You would need the Guardian Wi-Fi Security Camera, the CyberKey Smart Door Lock, and the Smart Home Hub Controller.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: We recommend the Guardian Wi-Fi Security Camera, the CyberKey Smart Door Lock, and the Smart Home Hub Controller for your security camera needs. They are controllable and viewable remotely via a smartphone.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "We recommend the Guardian Wi-Fi Security Camera, the CyberKey Smart Door Lock, and the Smart Home Hub Controller for your security camera needs. They are controllable and viewable remotely via a smartphone.\n"
          ]
        }
      ],
      "source": [
        "question = \"I want to buy two security cameras that need to be installed at my front door and living room. They should be controllable and viewable remotely via a smartphone. Can you help me with some recommendations?\"\n",
        "answer = agent.run(question)\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "ORDER_1 = \"20231127E45678\"\n",
        "ORDER_2 = \"20231125C12345\"\n",
        "\n",
        "ORDER_1_DETAIL = {\n",
        "    \"order_number\": ORDER_1,\n",
        "    \"status\": \"shipped\",\n",
        "    \"shipping_date\" : \"2023-11-27\",\n",
        "    \"estimated_delivered_date\": \"2023-12-01\",\n",
        "}\n",
        "\n",
        "ORDER_2_DETAIL = {\n",
        "    \"order_number\": ORDER_2,\n",
        "    \"status\": \"not Shipped\",\n",
        "    \"shipping_date\" : None,\n",
        "    \"estimated_delivered_date\": None,\n",
        "}\n",
        "\n",
        "import re\n",
        "\n",
        "@tool(\"Search Order\")\n",
        "def search_order(input:str)->str:\n",
        "    \"\"\"useful for when you need to answer questions about customers orders\"\"\"\n",
        "    if input.strip() == ORDER_1:\n",
        "        return json.dumps(ORDER_1_DETAIL)\n",
        "    elif input.strip() == ORDER_2:\n",
        "        return json.dumps(ORDER_2_DETAIL)\n",
        "    else:\n",
        "        return f\"Sorry, we could not find your order based on {input}\"\n",
        "\n",
        "tools = [search_order,recommend_product, faq]\n",
        "agent = initialize_agent(tools, llm=openai.OpenAI(temperature=0), agent=\"zero-shot-react-description\", verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out the status of the order\n",
            "Action: Search Order\n",
            "Action Input: 20231127D3478E\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSorry, we could not find your order based on 20231127D3478E\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out more information about the order\n",
            "Action: Search Order\n",
            "Action Input: 20231127D3478E\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSorry, we could not find your order based on 20231127D3478E\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to contact customer service\n",
            "Action: FAQ\n",
            "Action Input: order status\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new VectorDBQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m FBA stands for Fulfillment by Amazon.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Please contact customer service for more information about the status of your order 20231127D3478E. FBA stands for Fulfillment by Amazon.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Please contact customer service for more information about the status of your order 20231127D3478E. FBA stands for Fulfillment by Amazon.\n"
          ]
        }
      ],
      "source": [
        "question = \"I have an order with the order number 20231127D3478E. The order status shows as not delivered. Could you please help me check it?\"\n",
        "answer = agent.run(question)\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should check the order status first.\n",
            "Action: Search Order\n",
            "Action Input: 20231127D3478E\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSorry, we could not find your order based on 20231127D3478E.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should ask the user to confirm the order number.\n",
            "Action: Search Order\n",
            "Action Input: Confirm order number\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mWhat is your order number, please?\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should ask the user to enter the order number again.\n",
            "Action: Search Order\n",
            "Action Input: 20231127D3478E\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSorry, we could not find your order based on 20231127D3478E.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should ask the user to confirm the order number again.\n",
            "Action: Search Order\n",
            "Action Input: Confirm order number\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mWhat is your order number, please?\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should ask the user to enter the order number one more time.\n",
            "Action: Search Order\n",
            "Action Input: 20231127D3478E\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mSorry, we could not find your order based on 20231127D3478E.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should ask the user to contact customer service.\n",
            "Final Answer: We apologize for the inconvenience. Please contact our customer service team for further assistance.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "We apologize for the inconvenience. Please contact our customer service team for further assistance.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "@tool(\"Search Order\")\n",
        "def search_order(input:str)->str:\n",
        "    \"\"\"A tool that helps users check the latest order status and can handle the following situations:\n",
        "1. When the user does not enter an order number, it will ask the user for the order number.\n",
        "2. When the order number entered by the user cannot be found, it will ask the user to confirm whether the order number is correct for a second time.\n",
        "\"\"\"\n",
        "    pattern = r\"^\\d{8}[A-Z]\\d{5}$\"\n",
        "    match = re.search(pattern, input)\n",
        "\n",
        "    order_number = input\n",
        "    if match:\n",
        "        order_number = match.group(0)\n",
        "    else:\n",
        "        return \"What is your order number, please?\"\n",
        "    if order_number == ORDER_1:\n",
        "        return json.dumps(ORDER_1_DETAIL)\n",
        "    elif order_number == ORDER_2:\n",
        "        return json.dumps(ORDER_2_DETAIL)\n",
        "    else:\n",
        "        return f\"Sorry, we could not find your order based on {input}.\"\n",
        "\n",
        "tools = [search_order,recommend_product, faq]\n",
        "agent = initialize_agent(tools, llm=openai.OpenAI(temperature=0), agent=\"zero-shot-react-description\", verbose=True)\n",
        "\n",
        "question = \"I have an order with the order number 20231127D3478E. The order status shows as not delivered. Could you please help me check it?\"\n",
        "answer = agent.run(question)\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "answer_order_info = PromptTemplate(\n",
        "    template=\"Please reply to the user with the following order information: \\n\\n {order}?\", input_variables=[\"order\"]\n",
        ")\n",
        "answer_order_llm = LLMChain(llm=ChatOpenAI(temperature=0),  prompt=answer_order_info)\n",
        "\n",
        "@tool(\"Search Order\", return_direct=True)\n",
        "def search_order(input:str)->str:\n",
        "    \"\"\"useful for when you need to answer questions about customers orders\"\"\"\n",
        "    pattern = r\"^\\d{8}[A-Z]\\d{5}$\"\n",
        "    match = re.search(pattern, input)\n",
        "\n",
        "    order_number = input\n",
        "    if match:\n",
        "        order_number = match.group(0)\n",
        "    else:\n",
        "        return \"What is your order number, please?\"\n",
        "    if order_number == ORDER_1:\n",
        "        return answer_order_llm.run(json.dumps(ORDER_1_DETAIL))\n",
        "    elif order_number == ORDER_2:\n",
        "        return answer_order_llm.run(json.dumps(ORDER_2_DETAIL))\n",
        "    else:\n",
        "        return f\"Sorry, we could not find your order based on {input}.\"\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "tools = [search_order,recommend_product, faq]\n",
        "chatllm=ChatOpenAI(temperature=0)\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "conversation_agent = initialize_agent(tools, chatllm,\n",
        "                                      agent=\"conversational-react-description\",\n",
        "                                      memory=memory, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Search Order\n",
            "Action Input: I bought a drone on November 20th\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mWhat is your order number, please?\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "What is your order number, please?\n"
          ]
        }
      ],
      "source": [
        "question1 = \"I bought a drone on November 20th, but I haven't received it yet. Can you help me check on it?\"\n",
        "answer1 = conversation_agent.run(question1)\n",
        "print(answer1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Search Order\n",
            "Action Input: 20231127E45678\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mDear user,\n",
            "\n",
            "Thank you for your order. Here are the details:\n",
            "\n",
            "Order Number: 20231127E45678\n",
            "Status: Shipped\n",
            "Shipping Date: 2023-11-27\n",
            "Estimated Delivered Date: 2023-12-01\n",
            "\n",
            "If you have any further questions or concerns, please feel free to ask.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Dear user,\n",
            "\n",
            "Thank you for your order. Here are the details:\n",
            "\n",
            "Order Number: 20231127E45678\n",
            "Status: Shipped\n",
            "Shipping Date: 2023-11-27\n",
            "Estimated Delivered Date: 2023-12-01\n",
            "\n",
            "If you have any further questions or concerns, please feel free to ask.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n"
          ]
        }
      ],
      "source": [
        "question2 = \"My order number is 20231127E45678.\"\n",
        "answer2 = conversation_agent.run(question2)\n",
        "print(answer2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: FAQ\n",
            "Action Input: What is Amazon's return policy?\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new VectorDBQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m Amazon's return policy varies by item and seller, but in general, most items sold and fulfilled by Amazon can be returned within 30 days of receipt of shipment. For more information, please visit Amazon's Returns Support Center.\u001b[0m\n",
            "Thought:"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `Do I need to use a tool? No`",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "File \u001b[0;32m~/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/agents/agent.py:1032\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent\u001b[39m.\u001b[39;49mplan(\n\u001b[1;32m   1033\u001b[0m         intermediate_steps,\n\u001b[1;32m   1034\u001b[0m         callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1035\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs,\n\u001b[1;32m   1036\u001b[0m     )\n\u001b[1;32m   1037\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/agents/agent.py:636\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 636\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(full_output)\n",
            "File \u001b[0;32m~/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/agents/conversational/output_parser.py:26\u001b[0m, in \u001b[0;36mConvoOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m match:\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not parse LLM output: `\u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m action \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m)\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: `Do I need to use a tool? No`",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/fw/projects/PyCharm/ai_aesthetics/chap17/chap17.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/fw/projects/PyCharm/ai_aesthetics/chap17/chap17.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m question3 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhat is Amazon\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms return policy?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/fw/projects/PyCharm/ai_aesthetics/chap17/chap17.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m answer3 \u001b[39m=\u001b[39m conversation_agent\u001b[39m.\u001b[39;49mrun(question3)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/fw/projects/PyCharm/ai_aesthetics/chap17/chap17.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(answer3)\n",
            "File \u001b[0;32m~/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/chains/base.py:505\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    506\u001b[0m         _output_key\n\u001b[1;32m    507\u001b[0m     ]\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    511\u001b[0m         _output_key\n\u001b[1;32m    512\u001b[0m     ]\n",
            "File \u001b[0;32m~/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/chains/base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    311\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    312\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    314\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/chains/base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    297\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    298\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    299\u001b[0m     inputs,\n\u001b[1;32m    300\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[1;32m    301\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    305\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    306\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/agents/agent.py:1245\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1245\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m   1246\u001b[0m         name_to_tool_map,\n\u001b[1;32m   1247\u001b[0m         color_mapping,\n\u001b[1;32m   1248\u001b[0m         inputs,\n\u001b[1;32m   1249\u001b[0m         intermediate_steps,\n\u001b[1;32m   1250\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[1;32m   1251\u001b[0m     )\n\u001b[1;32m   1252\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1253\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[1;32m   1254\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[1;32m   1255\u001b[0m         )\n",
            "File \u001b[0;32m~/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/agents/agent.py:1043\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1041\u001b[0m     raise_error \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m raise_error:\n\u001b[0;32m-> 1043\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn output parsing error occurred. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1046\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1047\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis is the error: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[1;32m   1050\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
            "\u001b[0;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `Do I need to use a tool? No`"
          ]
        }
      ],
      "source": [
        "question3 = \"What is Amazon's return policy?\"\n",
        "answer3 = conversation_agent.run(question3)\n",
        "print(answer3)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai_aesthetics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
