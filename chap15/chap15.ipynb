{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%env OPENAI_API_KEY=<PUT_YOUR_API_KEY_HERE>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API says the answer is: \n",
            "\n",
            "264,672\n",
            "Python says the answer is: 266352\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import openai\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "llm = openai.OpenAI(model=\"text-davinci-003\", max_tokens=2048, temperature=0.5)\n",
        "multiply_prompt = PromptTemplate(template=\"Please calculate what {question} is?\", input_variables=[\"question\"])\n",
        "math_chain = LLMChain(llm=llm, prompt=multiply_prompt, output_key=\"answer\")\n",
        "answer = math_chain.run({\"question\": \"496 multiplied by 537\"})\n",
        "print(\"OpenAI API says the answer is:\", answer)\n",
        "\n",
        "python_answer = 496 * 537\n",
        "print(\"Python says the answer is:\", python_answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "answer = 496 * 537\n",
            "print(answer)\n",
            "\n",
            "Output: 265952\n"
          ]
        }
      ],
      "source": [
        "multiply_by_python_prompt = PromptTemplate(template=\"Please write a Python code to calculate {question}?\", input_variables=[\"question\"])\n",
        "math_chain = LLMChain(llm=llm, prompt=multiply_by_python_prompt, output_key=\"answer\")\n",
        "answer = math_chain.run({\"question\": \"496 multiplied by 537\"})\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Python REPL can execute arbitrary code. Use with caution.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "266352\n",
            "\n"
          ]
        }
      ],
      "source": [
        "multiply_by_python_prompt = PromptTemplate(template=\"Please write a Python code to calculate {question}?\", input_variables=[\"question\"])\n",
        "math_chain = LLMChain(llm=llm, prompt=multiply_by_python_prompt, output_key=\"answer\")\n",
        "answer_code = math_chain.run({\"question\": \"496 multiplied by 537\"})\n",
        "\n",
        "from langchain.utilities import PythonREPL\n",
        "python_repl = PythonREPL()\n",
        "result = python_repl.run(answer_code)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "Please calculate what 496 multiplied by 537 is?\u001b[32;1m\u001b[1;3m\n",
            "```text\n",
            "496 * 537\n",
            "```\n",
            "...numexpr.evaluate(\"496 * 537\")...\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m266352\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Answer: 266352\n"
          ]
        }
      ],
      "source": [
        "from langchain import LLMMathChain\n",
        "\n",
        "llm_math = LLMMathChain.from_llm(llm, verbose=True)\n",
        "result = llm_math.run(\"Please calculate what 496 multiplied by 537 is?\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'What is the weather like in Los Angeles today?', 'url': 'https://www.google.com/search?q=What+is+the+weather+like+in+Los+Angeles+today?', 'output': ' Sunny to partly cloudy. Temperature: 2780°C. Chance of Rain: 0%. Wind Speed: 3 km/h (2 mph).'}\n",
            " Sunny to partly cloudy. Temperature: 2780°C. Chance of Rain: 0%. Wind Speed: 3 km/h (2 mph).\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMRequestsChain\n",
        "\n",
        "template = \"\"\"Between >>> and <<< is the original search result from Google.\n",
        "Please extract the answer to the question '{query}' from it. If there is no relevant information, say \"Not found\".\n",
        "Please use the following format:\n",
        "Extracted:<answer or \"Not found\">\n",
        ">>> {requests_result} <<<\n",
        "Extracted:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"query\", \"requests_result\"],\n",
        "    template=template,\n",
        ")\n",
        "requests_chain = LLMRequestsChain(llm_chain = LLMChain(llm=openai.OpenAI(temperature=0), prompt=PROMPT))\n",
        "question = \"What is the weather like in Los Angeles today?\"\n",
        "inputs = {\n",
        "    \"query\": question,\n",
        "    \"url\": \"https://www.google.com/search?q=\" + question.replace(\" \", \"+\")\n",
        "}\n",
        "result=requests_chain(inputs)\n",
        "print(result)\n",
        "print(result['output'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Weather': 'Sunny to partly cloudy', 'Temperature': '2780', 'Rain Chance': '0', 'Wind Speed': '3 km/h'}\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def analyze_weather_forecast(text):\n",
        "    # Regular expression pattern\n",
        "    weather_pattern = r\"^(.*?)\\.\"\n",
        "    temperature_pattern = r\"Temperature: (\\d+)°C\"\n",
        "    rain_chance_pattern = r\"Chance of Rain: (\\d+)%\"\n",
        "    wind_speed_pattern = r\"Wind Speed: (\\d+ km/h)\"\n",
        "\n",
        "    # Search for matches\n",
        "    weather = re.search(weather_pattern, text)\n",
        "    temperature = re.search(temperature_pattern, text)\n",
        "    rain_chance = re.search(rain_chance_pattern, text)\n",
        "    wind_speed = re.search(wind_speed_pattern, text)\n",
        "\n",
        "    # Extract results\n",
        "    weather = weather.group(1) if weather else \"Not available\"\n",
        "    temperature = temperature.group(1) if temperature else \"Not available\"\n",
        "    rain_chance = rain_chance.group(1) if rain_chance else \"Not available\"\n",
        "    wind_speed = wind_speed.group(1) if wind_speed else \"Not available\"\n",
        "\n",
        "    return {\n",
        "        \"Weather\": weather,\n",
        "        \"Temperature\": temperature,\n",
        "        \"Rain Chance\": rain_chance,\n",
        "        \"Wind Speed\": wind_speed\n",
        "    }\n",
        "\n",
        "# Example.\n",
        "forecast_text = \"Sunny to partly cloudy. Temperature: 2780°C. Chance of Rain: 0%. Wind Speed: 3 km/h (2 mph).\"\n",
        "result = analyze_weather_forecast(forecast_text)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Weather': ' Sunny to partly cloudy', 'Temperature': '2780', 'Rain Chance': '0', 'Wind Speed': '3 km/h'}\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import TransformChain, SequentialChain\n",
        "\n",
        "def transform_func(inputs: dict) -> dict:\n",
        "    text = inputs[\"output\"]\n",
        "    return {\"weather_info\" : analyze_weather_forecast(text)}\n",
        "\n",
        "transformation_chain = TransformChain(input_variables=[\"output\"],\n",
        "                                      output_variables=[\"weather_info\"], transform=transform_func)\n",
        "\n",
        "final_chain = SequentialChain(chains=[requests_chain, transformation_chain],\n",
        "                              input_variables=[\"query\", \"url\"], output_variables=[\"weather_info\"])\n",
        "final_result = final_chain.run(inputs)\n",
        "print(final_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fw/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n",
            "Created a chunk of size 434, which is longer than the specified 256\n",
            "Created a chunk of size 466, which is longer than the specified 256\n",
            "/home/fw/miniconda3/envs/ai_aesthetics/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:251: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import faiss\n",
        "from langchain.text_splitter import SpacyTextSplitter\n",
        "from langchain.chains.retrieval_qa.base import VectorDBQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "llm = openai.OpenAI(temperature=0)\n",
        "loader = TextLoader('./data/amazon_faq.txt')\n",
        "documents = loader.load()\n",
        "text_splitter = SpacyTextSplitter(chunk_size=256, pipeline=\"en_core_web_sm\")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "docsearch = faiss.FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "faq_chain = VectorDBQA.from_chain_type(llm=llm, vectorstore=docsearch, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new VectorDBQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " FBA stands for Fulfillment by Amazon. It is a pay-as-you-go fulfillment service where you pay for storage space and fulfillment of each sale. The cost of shipping is included in your fees, with no extra charge for Amazon Prime FREE Two-Day Shipping and free shipping on eligible orders.\n"
          ]
        }
      ],
      "source": [
        "question = \"What is FBA?\"\n",
        "result = faq_chain.run(question)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new VectorDBQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Top selling items on any given day may include books, baby items, electronics, kitchen supplies, outdoor gear—the list goes on. Check out Amazon Best Sellers for an hourly update with the most popular products based on sales.\n"
          ]
        }
      ],
      "source": [
        "question = \"What sells the most in Amazon’s store?\"\n",
        "result = faq_chain.run(question)\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai_aesthetics",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
